{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614ef48b-14f0-4de1-a243-6b961927a35c",
   "metadata": {},
   "source": [
    "### Baseline models to consider:\n",
    " - BART model from the work of SciTech News\n",
    " - Zero and Few-shot prompting of LLAMA-3\n",
    " - Fine-tuned LLAMA-3\n",
    " - BART model extended with conversation between (non) fine-tuned LLAMA-3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2276a5-e797-43f2-96d8-ce46e0a07590",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b596b939-bf57-4b15-91d4-e3be81dd54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c06329-6589-4132-990c-ec9d1f9119ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/swordfish-pool2/milad/hf-cache'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/mnt/swordfish-pool2/milad/hf-cache'\n",
    "os.environ['OPENAI_API_KEY'] = 'zTbZNk16Ik1pZnqLn38ZT3BlbkFJImq3pd7widkr7RzsC771'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "sys.path.append('./src-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271bc6e9-d024-41ea-bbf6-9695121cecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import datasets\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tabulate import tabulate\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, pipeline\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dca823a-e5b5-4c79-965e-8bf9d943c43f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import utils\n",
    "import prompts\n",
    "import datadreamer_generation\n",
    "from llm_based_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6dfdbc1-1416-4d71-9104-55a3bcf0f56c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_path = '/mnt/swordfish-pool2/milad/communicating-science-to-the-public/eval_experiment_500/baseline_llama3_gen_conv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36134e5f-4d62-4260-8c2e-4d4f7a1c8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = datasets.load_from_disk(ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f0f83c3-421b-47a5-a402-c09610837906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['paper_id', 'paper_title', 'paper_text', 'prompt', 'completion', 'pr-article', 'topic', '__index_level_0__', 'generated_conversation', 'conversation'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431e0dbe-c81b-438e-a30a-7918717f64a9",
   "metadata": {},
   "source": [
    "### Zero and few shot journalistic summarization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e7d5ef-6a67-4903-82ba-b4314fc94ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datadreamer.llms import HFTransformers, ParallelLLM, OpenAI\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "q=BitsAndBytesConfig(load_in_8bit=True)\n",
    "llama3 = HFTransformers(\"meta-llama/Meta-Llama-3-8B-Instruct\", device='auto', quantization_config=q, dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b644e46-237d-444d-bb59-b2ccbb599960",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = datasets.load_from_disk(ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b67f1ccc-72f4-4bac-b156-ed38e17b8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = '/mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/baseline-generation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f27d615-a91a-4670-9ce4-d0b96a6bc485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Initialized. 🚀 Dreaming to folder: /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/baseline-generation//generated-prs/baseline_pr_generationbaseline_pr_generation\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds' finished and is saved to disk. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' will run lazily. 🥱\n",
      "/local/nlp/milad/code/llms-as-science-communicators/src-py/datadreamer_generation.py:332: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify map(..., total_num_rows=#) or, to disable this warning, specify map(.., auto_progress = False)\n",
      "  datasource = datasource.map(lambda row: {'inputs_truncated': truncate_text(encoding, row['inputs'], max_input_tokens)})\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' will run lazily. 🥱\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Please write a press release article to communicate the science presented in the following scientific paper. Your output should be:\n",
      "        \"Press Release Article\": \"The press release article about the paper\"\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] [ 🧠 HFTransformers (meta-llama/Meta-Llama-3-8B-Instruct)] Loading...\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] [ 🧠 HFTransformers (meta-llama/Meta-Llama-3-8B-Instruct)] Finished loading.\n",
      "/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 10 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 20 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 30 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 40 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 50 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 60 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 70 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 80 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 90 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 100 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 110 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 120 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 130 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 140 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 150 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 160 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 170 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 180 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 190 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 200 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 210 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 220 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 230 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 240 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 250 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 260 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 270 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 280 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 290 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 300 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 310 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 320 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 330 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 340 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 350 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 360 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 370 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 380 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 390 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 400 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 410 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 420 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 430 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 440 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 450 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 460 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 470 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 480 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 490 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 500 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' finished and is saved to disk. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings (select_columns)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings (select_columns)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns))' is running. ⏳\n",
      "/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datadreamer/steps/step_operations.py:383: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify LazyRows(..., total_num_rows=#) or, to disable this warning, specify LazyRows(.., auto_progress = False)\n",
      "  return LazyRows(\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns))' will run lazily. 🥱\n",
      "/local/nlp/milad/code/llms-as-science-communicators/src-py/datadreamer_generation.py:350: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify map(..., total_num_rows=#) or, to disable this warning, specify map(.., auto_progress = False)\n",
      "  zipped_step = zipped_step.map(lambda row: parse_pr_article(row))\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns)) (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns)) (map)' will run lazily. 🥱\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns))' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns)) (map)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Done. ✨ Results in folder: /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/baseline-generation//generated-prs/baseline_pr_generationbaseline_pr_generation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671c3485ba0a4124b15e396ee770547d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = prompts.baseline_pr_generation\n",
    "prompt['inputs']['Scientific paper'] = 'paper_text'\n",
    "baseline_pr_generation_res = datadreamer_generation.generate_pr_articles(llama3, sample_test, ds_path + '/generated-prs/'  + prompt['strategy_name'], \n",
    "                                                                         tokenizer, prompt, max_input_tokens=1200, hub_name=None)\n",
    "baseline_pr_generation_res.save_to_disk(ds_path + '/generated-prs/'  + prompt['strategy_name'] + '_final_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d366bacf-de66-4956-aab4-8ea3879fcc4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Initialized. 🚀 Dreaming to folder: /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/baseline-generation//generated-prs/baseline_pr_generation_cotbaseline_pr_generation_cot\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds' finished and is saved to disk. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' will run lazily. 🥱\n",
      "/local/nlp/milad/code/llms-as-science-communicators/src-py/datadreamer_generation.py:332: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify map(..., total_num_rows=#) or, to disable this warning, specify map(.., auto_progress = False)\n",
      "  datasource = datasource.map(lambda row: {'inputs_truncated': truncate_text(encoding, row['inputs'], max_input_tokens)})\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' will run lazily. 🥱\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Please write a press release article to communicate the science presented in the following paper.\n",
      "        Before generating the press release, think step by step about the social impact of the research paper, the innovative aspects of the paper and how it is different from other research on the same topic, and how to communicate the problem, the approach and the results of the paper in a simple and accessible lanuage. Finally output the press release in the following format:\n",
      "        \"Press Release Article\": \"The press release article about the paper\"\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' finished running lazily. 🎉\n",
      "/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 10 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 20 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 30 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 40 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 50 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 60 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 70 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 80 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 90 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 100 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 110 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 120 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 130 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 140 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 150 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 160 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 170 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 180 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 190 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 200 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 210 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 220 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 230 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 240 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 250 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 260 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 270 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 280 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 290 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 300 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 310 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 320 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 330 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 340 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 350 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 360 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 370 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 380 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 390 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 400 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 410 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 420 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 430 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 440 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 450 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 460 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 470 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 480 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 490 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 500 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' finished and is saved to disk. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings (select_columns)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings (select_columns)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns))' is running. ⏳\n",
      "/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datadreamer/steps/step_operations.py:383: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify LazyRows(..., total_num_rows=#) or, to disable this warning, specify LazyRows(.., auto_progress = False)\n",
      "  return LazyRows(\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns))' will run lazily. 🥱\n",
      "/local/nlp/milad/code/llms-as-science-communicators/src-py/datadreamer_generation.py:350: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify map(..., total_num_rows=#) or, to disable this warning, specify map(.., auto_progress = False)\n",
      "  zipped_step = zipped_step.map(lambda row: parse_pr_article(row))\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns)) (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns)) (map)' will run lazily. 🥱\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find PR Article in the output\n",
      "Failed to find PR Article in the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns))' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns)) (map)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Done. ✨ Results in folder: /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/baseline-generation//generated-prs/baseline_pr_generation_cotbaseline_pr_generation_cot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2361d728534270bd65b052d3386a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = prompts.baseline_pr_generation_cot\n",
    "prompt['inputs']['Scientific paper'] = 'paper_text'\n",
    "baseline_pr_generation_res = datadreamer_generation.generate_pr_articles(llama3, sample_test, ds_path + '/generated-prs/'  + prompt['strategy_name'], \n",
    "                                                                         tokenizer, prompt, max_input_tokens=1200, hub_name=None)\n",
    "baseline_pr_generation_res.save_to_disk(ds_path + '/generated-prs/'  + prompt['strategy_name'] + '_final_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb83aa6a-ca30-4d88-9c37-229562f74fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Initialized. 🚀 Dreaming to folder: /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/baseline-generation//generated-prs/baseline_pr_generation_w_convbaseline_pr_generation_w_conv\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds' finished and is saved to disk. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' will run lazily. 🥱\n",
      "/local/nlp/milad/code/llms-as-science-communicators/src-py/datadreamer_generation.py:332: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify map(..., total_num_rows=#) or, to disable this warning, specify map(.., auto_progress = False)\n",
      "  datasource = datasource.map(lambda row: {'inputs_truncated': truncate_text(encoding, row['inputs'], max_input_tokens)})\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' will run lazily. 🥱\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' is running. ⏳\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Please write a press release article to communicate the science presented in the following paper.\n",
      "        Before generating the press release, generate a conversation between the paper's author and a journalist where they discuss the social impact of the research paper, the innovative aspects of the paper and how it is different from other research on the same topic. The author explains the paper in a very simple and accessible language to the journalist. Finally output the press release in the following format:\n",
      "        \"Press Release Article\": \"The press release article about the paper\"        \n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' finished running lazily. 🎉\n",
      "/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 10 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 20 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 30 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 40 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 50 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 60 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 70 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 80 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 90 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 100 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 110 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 120 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 130 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 140 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 150 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 160 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 170 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 180 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 190 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 200 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 210 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 220 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 230 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 240 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 250 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 260 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 270 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 280 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 290 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 300 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 310 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 320 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 330 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 340 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 350 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 360 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 370 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 380 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 390 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 400 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 410 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 420 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 430 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 440 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 450 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 460 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 470 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 480 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 490 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 500 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' finished and is saved to disk. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings (select_columns)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings (select_columns)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns))' is running. ⏳\n",
      "/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datadreamer/steps/step_operations.py:383: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify LazyRows(..., total_num_rows=#) or, to disable this warning, specify LazyRows(.., auto_progress = False)\n",
      "  return LazyRows(\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns))' will run lazily. 🥱\n",
      "/local/nlp/milad/code/llms-as-science-communicators/src-py/datadreamer_generation.py:350: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify map(..., total_num_rows=#) or, to disable this warning, specify map(.., auto_progress = False)\n",
      "  zipped_step = zipped_step.map(lambda row: parse_pr_article(row))\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns)) (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns)) (map)' will run lazily. 🥱\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find PR Article in the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns))' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map), pr-writings (select_columns)) (map)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Done. ✨ Results in folder: /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/baseline-generation//generated-prs/baseline_pr_generation_w_convbaseline_pr_generation_w_conv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26b6c24ca054ab9ac1f5c8ec1e70169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = prompts.baseline_pr_generation_w_conv\n",
    "prompt['inputs']['Scientific paper'] = 'paper_text'\n",
    "baseline_pr_generation_res = datadreamer_generation.generate_pr_articles(llama3, sample_test, ds_path + '/generated-prs/'  + prompt['strategy_name'], \n",
    "                                                                         tokenizer, prompt, max_input_tokens=1200, hub_name=None)\n",
    "baseline_pr_generation_res.save_to_disk(ds_path + '/generated-prs/'  + prompt['strategy_name'] + '_final_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73a83725-4d1d-4107-a4cf-70d0d84772ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0425d8f7f34438af34358770637bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_test = sample_test.map(lambda row: {'generated-conversation-as-str': '\\n'.join(['{}: {}'.format('Journalist', x['content']) if x['role'] == 'assistant' else '{}: {}'.format('Researcher', x['content']) for x in row['generated_conversation'][1:]])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31970f1f-b54b-49f0-8b72-ea7c13c94c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Initialized. 🚀 Dreaming to folder: /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/baseline-generation/pr_generation_by_conv_summarization\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds' finished and is saved to disk. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' will run lazily. 🥱\n",
      "/home/ma4608/communicating-science-to-the-public/src/baselines.py:77: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify map(..., total_num_rows=#) or, to disable this warning, specify map(.., auto_progress = False)\n",
      "  datasource = datasource.map(lambda row: {'inputs_len': len(encoding.encode(row['inputs']))})\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' will run lazily. 🥱\n",
      "/home/ma4608/communicating-science-to-the-public/src/baselines.py:78: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify filter(..., total_num_rows=#) or, to disable this warning, specify filter(.., auto_progress = False)\n",
      "  datasource = datasource.filter(lambda row: row['inputs_len'] < max_input_tokens)\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map) (filter)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map) (filter)' will run lazily. 🥱\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' is running. ⏳\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Please write a press release article to communicate the science presented in the following paper. The press-release should summarize the main points in the given conversation. The output should have the following format:\n",
      "        \"Press Release Article\": \"The press release article about the paper\"        \n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'original_ds (map) (map) (filter)' finished running lazily. 🎉\n",
      "/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 10 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 20 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 30 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 40 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 50 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 60 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 70 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 80 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 90 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 100 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 110 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 120 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 130 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 140 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 150 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 160 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 170 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 180 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 190 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 200 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 210 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 220 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 230 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 240 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 250 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 260 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 270 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 280 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 290 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 300 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 310 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 320 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 330 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 340 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 350 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 360 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 370 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 380 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 390 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 400 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 410 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 420 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 430 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 440 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 450 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 460 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 470 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 480 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 490 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' progress: 500 row(s) 🔄\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings' finished and is saved to disk. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings (select_columns)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'pr-writings (select_columns)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map) (filter), pr-writings (select_columns))' is running. ⏳\n",
      "/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datadreamer/steps/step_operations.py:383: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify LazyRows(..., total_num_rows=#) or, to disable this warning, specify LazyRows(.., auto_progress = False)\n",
      "  return LazyRows(\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map) (filter), pr-writings (select_columns))' will run lazily. 🥱\n",
      "/home/ma4608/communicating-science-to-the-public/src/baselines.py:94: UserWarning: You did not specify `total_num_rows`, so we cannot automatically update the progress % for this step. Either specify map(..., total_num_rows=#) or, to disable this warning, specify map(.., auto_progress = False)\n",
      "  zipped_step = zipped_step.map(lambda row: parse_pr_article(row))\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map) (filter), pr-writings (select_columns)) (map)' is running. ⏳\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map) (filter), pr-writings (select_columns)) (map)' will run lazily. 🥱\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find PR Article in the output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map) (filter), pr-writings (select_columns))' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Step 'zipped(original_ds (map) (map) (filter), pr-writings (select_columns)) (map)' finished running lazily. 🎉\n",
      "[ \u001b[35m🤖 Data\u001b[33mDr\u001b[31mea\u001b[35mmer\u001b[0m 💤 ] Done. ✨ Results in folder: /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/baseline-generation/pr_generation_by_conv_summarization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6006a403084a13aa5a437b5cf45497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = prompts.pr_generation_by_conv_summarization\n",
    "prompt['inputs']['Conversation'] = 'generated-conversation-as-str'\n",
    "pr_generation_w_conv_res = baselines.generate_pr_articles(llama3, sample_test, ds_path, tokenizer, prompt, hub_name=None)\n",
    "pr_generation_w_conv_res.save_to_disk(ds_path + prompt['strategy_name'] + '_final_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90031709-7c27-4283-b8cb-6b882141cb55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Press Release Article**\n",
      "\n",
      "**Scientists Search for Dark Matter with Global Network of Optical Magnetometers**\n",
      "\n",
      "A team of scientists has conducted a groundbreaking search for dark matter using a global network of optical magnetometers, known as GNOME (Global Network of Optical Magnetometers for Exotic physics searches). The search, published in a recent scientific paper, aimed to detect the presence of axion-like particles, a type of dark matter candidate, by monitoring the Earth's passage through hypothetical domain walls.\n",
      "\n",
      "Dark matter is a mysterious substance that makes up approximately 80% of the universe's mass, yet its nature remains unknown. Axion-like particles are a popular theory for explaining dark matter's existence. These particles can form stable, macroscopic field configurations, such as topological defects, which could concentrate dark matter density into distinct, compact regions.\n",
      "\n",
      "The GNOME network, comprising over a dozen optical atomic magnetometers located worldwide, was used to search for transient signals associated with the passage of the Earth through these hypothetical domain walls. The magnetometers measure the Larmor spin precession of optically polarized atoms, allowing them to detect tiny changes in the magnetic field caused by the interaction between the axion-like particles and atomic spins.\n",
      "\n",
      "The analysis of the data from a continuous month-long operation of GNOME found no statistically significant signals, placing experimental constraints on dark matter scenarios involving axion-like particles. While the search did not detect any evidence of dark matter, it demonstrates the ability of GNOME to explore previously unconstrained regions of the dark matter parameter space.\n",
      "\n",
      "\"This search marks a significant milestone in the quest to understand dark matter,\" said [Name], lead author of the study. \"By using a global network of magnetometers, we can cover a vast range of possible dark matter scenarios and potentially detect signals that would be undetectable with a single, local experiment.\"\n",
      "\n",
      "The GNOME network is a unique tool for exploring the properties of dark matter, and its results have important implications for our understanding of the universe. Future searches with GNOME will continue to push the boundaries of our knowledge, potentially uncovering new insights into the nature of dark matter.\n",
      "\n",
      "**Contact:**\n",
      "[Name]\n",
      "[Email]\n",
      "[Phone]\n",
      "\n",
      "**About the Research:**\n",
      "The research was published in [Journal Name] and is available online at [DOI]. The study was conducted by a team of scientists from [Institution Name] and [Institution Name].\n",
      "++++++++++++++\n",
      "**Press Release Article**\n",
      "\n",
      "**Scientists Discover New Way to Search for Dark Matter**\n",
      "\n",
      "A team of scientists has made a groundbreaking discovery in the search for dark matter, a mysterious substance that makes up approximately 80% of the universe. Using a global network of optical magnetometers, researchers have developed a new method to detect dark matter, which could revolutionize our understanding of the universe.\n",
      "\n",
      "Dark matter is a type of matter that does not interact with light, making it invisible to our telescopes. Scientists have long been searching for ways to detect it, as it plays a crucial role in the formation and evolution of galaxies. The new method, developed by a team of scientists from around the world, uses a network of optical magnetometers to detect the subtle effects of dark matter on atomic spins.\n",
      "\n",
      "The team, led by [Name], used a global network of optical magnetometers, known as GNOME (Global Network of Optical Magnetometers for Exotic physics searches), to search for dark matter. The network consists of over a dozen magnetometers located in Europe, North America, Asia, the Middle East, and Australia. Each magnetometer measures the tiny changes in the magnetic field caused by the passage of dark matter objects through the Earth.\n",
      "\n",
      "The researchers analyzed data from a month-long operation of the GNOME network, searching for patterns of signals that could indicate the presence of dark matter. While they did not find any statistically significant signals, their analysis placed experimental constraints on certain dark matter scenarios, providing valuable insights into the nature of dark matter.\n",
      "\n",
      "\"This is a major breakthrough in the search for dark matter,\" said [Name], lead author of the study. \"Our new method allows us to detect dark matter in a way that was previously impossible. We are excited to continue our research and explore the mysteries of the universe.\"\n",
      "\n",
      "The discovery has significant implications for our understanding of the universe and the search for dark matter. It could also lead to new technologies and applications in fields such as astronomy, physics, and materials science.\n",
      "\n",
      "The study was published in [Journal Name] and is available online.\n",
      "\n",
      "**Contact:**\n",
      "[Name]\n",
      "[Email]\n",
      "[Phone]\n",
      "\n",
      "**About [Institution/Organization]:**\n",
      "[Institution/Organization] is a leading research institution dedicated to advancing our understanding of the universe and the laws of physics.\n",
      "++++++++++++++\n",
      "**Conversation between the author and the journalist**\n",
      "\n",
      "Journalist: Congratulations on your new paper! Can you tell me a bit about what you've discovered?\n",
      "\n",
      "Author: Thank you! We've been studying a type of dark matter called axion-like particles, which are thought to make up a significant portion of the universe. We've developed a new way to detect these particles using a global network of optical magnetometers.\n",
      "\n",
      "Journalist: That sounds fascinating. How does this research impact society?\n",
      "\n",
      "Author: Well, understanding dark matter is crucial for our understanding of the universe and its evolution. It could also have implications for our understanding of the fundamental laws of physics. Additionally, if we can detect dark matter, it could lead to breakthroughs in fields like medicine and technology.\n",
      "\n",
      "Journalist: That's impressive. What makes your research innovative?\n",
      "\n",
      "Author: We're using a unique approach to detect dark matter by looking for patterns in the signals from a global network of magnetometers. This allows us to search for dark matter in a way that's not possible with other methods.\n",
      "\n",
      "Journalist: How does your research differ from other research on the same topic?\n",
      "\n",
      "Author: Our research focuses on a specific type of dark matter, axion-like particles, and uses a novel detection method. Other research has focused on different types of dark matter or used different detection methods.\n",
      "\n",
      "Journalist: Can you explain the paper in simple terms?\n",
      "\n",
      "Author: Sure thing! Imagine you're trying to detect a very faint signal in a noisy environment. We're using a network of magnetometers to detect the signal of dark matter particles passing through the Earth. We're looking for patterns in the signals that could indicate the presence of dark matter.\n",
      "\n",
      "**Press Release Article**\n",
      "\n",
      "**Breakthrough in Dark Matter Detection: Global Network of Magnetometers Reveals New Insights**\n",
      "\n",
      "A team of scientists has made a groundbreaking discovery in the field of dark matter detection, using a global network of optical magnetometers to search for axion-like particles. The research, published in a recent paper, has opened up new avenues for understanding the fundamental laws of physics and could have significant implications for fields like medicine and technology.\n",
      "\n",
      "The team, led by [Author's Name], developed a novel detection method that uses a network of magnetometers to search for patterns in the signals of dark matter particles passing through the Earth. This approach allows for a more sensitive and accurate detection of dark matter than previous methods.\n",
      "\n",
      "The research focuses on axion-like particles, a type of dark matter that is thought to make up a significant portion of the universe. The team used a global network of magnetometers, known as GNOME, to search for signals of dark matter particles passing through the Earth.\n",
      "\n",
      "\"We're excited about the potential implications of this research,\" said [Author's Name]. \"Understanding dark matter could lead to breakthroughs in fields like medicine and technology, and this new detection method could be a game-changer in the field.\"\n",
      "\n",
      "The paper, titled [Paper Title], is a significant step forward in the search for dark matter and could have far-reaching implications for our understanding of the universe.\n",
      "++++++++++++++\n",
      "**Press Release Article:**\n",
      "\n",
      "**Groundbreaking Experiment Seeks to Uncover Secrets of Dark Matter**\n",
      "\n",
      "A team of researchers has made a significant breakthrough in the search for dark matter, a mysterious and elusive component of the universe. The Global Network of Optical Magnetometers for Exotic physics (GNOME) experiment, a collaborative effort between scientists from around the world, has successfully detected patterns in data that could be indicative of dark matter signals.\n",
      "\n",
      "The GNOME experiment uses a global network of optical magnetometers to detect dark matter interactions with atomic spins. This innovative approach allows researchers to search for dark matter signals in a way that is more sensitive and direct than traditional methods. The experiment has achieved a sensitivity of around 10^-18 GeV/c^2, a significant milestone in the search for dark matter.\n",
      "\n",
      "The researchers used a combination of machine learning algorithms and signal processing techniques to analyze the data and identify patterns that could be indicative of dark matter signals. The algorithm was able to detect signals that were consistent with the expected properties of dark matter interactions with atomic spins.\n",
      "\n",
      "The next phase of the experiment aims to further improve the sensitivity and scope of the search. The team plans to upgrade the magnetometers, increase the number of magnetometers, expand the search volume, and improve the data analysis algorithms. The researchers are also collaborating with other experiments and researchers to combine their efforts and increase their chances of detecting dark matter signals.\n",
      "\n",
      "The GNOME experiment has the potential to make a significant contribution to our understanding of the universe and the nature of dark matter. The team's findings have significant implications for the field of particle physics and cosmology, and could potentially lead to a deeper understanding of the fundamental laws of nature.\n",
      "\n",
      "**Contact:**\n",
      "For more information, please contact [Name], lead researcher of the GNOME experiment, at [Email] or [Phone number].\n",
      "\n",
      "**About the GNOME Experiment:**\n",
      "The Global Network of Optical Magnetometers for Exotic physics (GNOME) experiment is a collaborative effort between scientists from around the world. The experiment uses a global network of optical magnetometers to detect dark matter interactions with atomic spins. The team is led by [Name] and includes researchers from [Institutions].\n"
     ]
    }
   ],
   "source": [
    "#clm='parsed-pr-article'\n",
    "clm='gen-pr'\n",
    "row=0\n",
    "print(baseline_pr_generation_res[clm][row])\n",
    "print('++++++++++++++')\n",
    "print(baseline_pr_generation_cot_res[clm][row])\n",
    "print('++++++++++++++')\n",
    "print(baseline_pr_generation_w_conv_res[clm][row])\n",
    "print('++++++++++++++')\n",
    "print(pr_generation_w_conv_res[clm][row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f73a3d12-93c6-48bd-9da8-5b92efbc1fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the two trained llms\n",
    "# ds_path = '/mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/llama3-trained-on-llama3-for-1-epochs/'\n",
    "\n",
    "# q=BitsAndBytesConfig(load_in_8bit=True)\n",
    "# llama3 = HFTransformers(\"meta-llama/Meta-Llama-3-8B-Instruct\", device='auto', adapter_name='miladalsh/llama3-trained-on-llama3-for-1-epochs', \n",
    "#                         quantization_config=q, dtype=torch.bfloat16)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# prompt = prompts.baseline_pr_generation_w_conv\n",
    "# prompt['inputs']['Scientific paper'] = 'sc-intro'\n",
    "# pr_generation_w_conv_res = baselines.generate_pr_articles(llama3, sample_test, ds_path, tokenizer, prompt, hub_name=None)\n",
    "# pr_generation_w_conv_res.save_to_disk(ds_path + prompt['strategy_name'] + 'final_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c572ce1-b778-4236-ae84-69357351a313",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9e53e8d-397e-43ab-900b-709c834f0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = '/mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c740373e-d9c7-41a8-8563-9ed141fa37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pr_generation_res = datasets.load_from_disk(ds_path + '/baseline-generation/' + 'baseline_pr_generation_final_ds')\n",
    "baseline_pr_generation_cot_res = datasets.load_from_disk(ds_path + '/baseline-generation/' + 'baseline_pr_generation_cot_final_ds')\n",
    "baseline_pr_generation_conv_res = datasets.load_from_disk(ds_path + '/baseline-generation/' + 'baseline_pr_generation_w_conv_final_ds')\n",
    "pr_generation_conv_res = datasets.load_from_disk(ds_path + '/baseline-generation/' + 'pr_generation_by_conv_summarization_final_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6272993-fa3f-41b4-ba60-85a400814b03",
   "metadata": {},
   "source": [
    "#### Basic Eval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5186d5-fc2a-4aa8-992f-46f83da8f0c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "eval_results = {}\n",
    "\n",
    "eval_results['baseline_pr_generation'] = utils.evaluate_text_similarity(baseline_pr_generation_res['parsed-pr-article'],  baseline_pr_generation_res['pr-article'])\n",
    "eval_results['baseline_pr_generation_cot'] = utils.evaluate_text_similarity(baseline_pr_generation_cot_res['parsed-pr-article'],  baseline_pr_generation_cot_res['pr-article'])\n",
    "eval_results['baseline_pr_generation_w_conv'] = utils.evaluate_text_similarity(baseline_pr_generation_conv_res['parsed-pr-article'],  baseline_pr_generation_conv_res['pr-article'])\n",
    "eval_results['pr_generation_w_conv'] = utils.evaluate_text_similarity(pr_generation_conv_res['parsed-pr-article'],  pr_generation_conv_res['pr-article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ebf5736-adf9-4380-b623-83bd160416ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#baseline_pr_generation_cot_res['gen-pr'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7294db6-9bc6-48f1-a853-1878a56f31da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#baseline_pr_generation_cot_res['parsed-pr-article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63d6492b-d590-468b-a806-f8ee2d83b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                            Rouge-1    Rouge-L    BERT-f1\n",
      "-----------------------------  ---------  ---------  ---------\n",
      "baseline_pr_generation             0.434      0.181      0.837\n",
      "baseline_pr_generation_cot         0.435      0.178      0.835\n",
      "baseline_pr_generation_w_conv      0.38       0.167      0.834\n",
      "pr_generation_w_conv               0.405      0.172      0.829\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(\n",
    "    [[name] + list(eval_res.values())[:3] for name, eval_res in eval_results.items()],\n",
    "    headers=['Model', 'Rouge-1', 'Rouge-L', 'BERT-f1']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e4a79-c663-4067-a0db-2a19de336e97",
   "metadata": {},
   "source": [
    "#### LLM-based evalaution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27bfbf96-53e6-4d4a-9fa8-56a84a0afd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grdound_truth_ds = baseline_pr_generation_res.map(lambda row: {'parsed-pr-article': row['pr-summary-and-article']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c2a0fe1-635f-4cd0-839a-818a498be7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "press_release_datasets = {\n",
    "    'baseline_pr_generation' : [ datasets.load_from_disk(ds_path + '/baseline-generation/' + 'baseline_pr_generation_final_ds'), ds_path + '/baseline-generation/' + 'baseline_pr_generation_final_ds'],\n",
    "    'baseline_pr_generation_cot': [datasets.load_from_disk(ds_path + '/baseline-generation/' + 'baseline_pr_generation_cot_final_ds'),ds_path + '/baseline-generation/' + 'baseline_pr_generation_cot_final_ds'],\n",
    "    'baseline_pr_generation_w_conv': [datasets.load_from_disk(ds_path + '/baseline-generation/' + 'baseline_pr_generation_w_conv_final_ds'), ds_path + '/baseline-generation/' + 'baseline_pr_generation_w_conv_final_ds'],\n",
    "    'pr_generation_w_conv': [datasets.load_from_disk(ds_path + '/baseline-generation/' + 'pr_generation_by_conv_summarization_final_ds'), ds_path + '/baseline-generation/' + 'pr_generation_by_conv_summarization_final_ds'],\n",
    "    'gt_press_release' : [grdound_truth_ds, ds_path + '/gt-press-release'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bd6ef-f35b-4891-949c-92723a7579a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases//baseline-generation/baseline_pr_generation_final_ds from already saved file\n",
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases//baseline-generation/baseline_pr_generation_cot_final_ds from already saved file\n",
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases//baseline-generation/baseline_pr_generation_w_conv_final_ds from already saved file\n",
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/generated-press-releases//baseline-generation/pr_generation_by_conv_summarization_final_ds from already saved file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/494 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "prompts_to_eval = [prompts.pr_clarity_eval_prompt, prompts.pr_scientific_context_eval_prompt, prompts.pr_societal_context_eval_prompt]\n",
    "\n",
    "llm_eval_results = llm_based_evaluation(prompts_to_eval, press_release_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71969268-86d8-4b57-b0a6-184616a82c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt                           Scientific Context    Social Context    Accessibility    Relevance\n",
      "-----------------------------  --------------------  ----------------  ---------------  -----------\n",
      "baseline_pr_generation                         1.74              1.95             3.6          2.43\n",
      "baseline_pr_generation_cot                     1.75              1.99             3.8          2.51\n",
      "baseline_pr_generation_w_conv                  1.7               2.04             3.86         2.53\n",
      "pr_generation_w_conv                           1.64              2.06             3.38         2.36\n",
      "gt_press_release                               2.48              2.22             4.39         3.03\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(\n",
    "        [[name] + get_llm_avg_scores(res) for name, res in llm_eval_results.items()],\n",
    "        headers=['Prompt', 'Scientific Context', 'Social Context', 'Accessibility', 'Relevance', 'Avg']\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
