{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43c8d27-0b47-46ac-a3f7-e5a02134e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d78efec-68b0-47f6-8d88-af0cd01c16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/swordfish-pool2/milad/hf-cache-new'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/mnt/swordfish-pool2/milad/hf-cache-new'\n",
    "os.environ[\"OPENAI_API_KEY\"]= 'xxx'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "sys.path.append('./src-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24b5e38-93dc-4098-97de-bb786a750a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "%autoreload\n",
    "import utils\n",
    "import prompts\n",
    "import random\n",
    "\n",
    "from tabulate import tabulate\n",
    "import tiktoken\n",
    "from llm_based_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d903fa8b-3c9e-4d0c-9a90-00c414488647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e08009fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "keys = json.load(open('./keys.json'))\n",
    "for key, val in keys.items():\n",
    "    os.environ[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de285da-4e35-4041-8aa8-956e164feb64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(os.environ['hf_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "846f3f93-4394-4627-be70-6bd557823095",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/mnt/swordfish-pool2/milad/communicating-science-to-the-public/'\n",
    "models_folder = \"/mnt/swordfish-pool2/milad/communicating-science-to-the-public/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6a4d8a7-48f5-42a8-80f8-757e6a889e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d647b70-c4cd-4831-a450-1a8d0b6ac1a6",
   "metadata": {},
   "source": [
    "### Evaluate Science Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38243aa0-986e-4b8f-acfd-40ab8416f2a8",
   "metadata": {},
   "source": [
    "- Now we will evalaute the following models on a sample from the test set using only the generic prompt\n",
    "    - LLAMA-3 baseline\n",
    "    - Qwen baseline\n",
    "    - LLAMA-3 fine-tuned on DeepSeek generated conversations\n",
    "    - Qwen  fine-tuned on DeepSeek generated conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c9f30f-f44a-4315-bf1d-2b75f97402b7",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e7a4a-b70e-44ea-b373-c6441e21a5dc",
   "metadata": {},
   "source": [
    "#### Basic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15431a5-748f-4273-82a1-6b9570850875",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = '/mnt/swordfish-pool2/milad/communicating-science-to-the-public'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32572be9-6d3b-4a0b-b1ef-794023c478d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_convs = {\n",
    "    #'gpt3-baseline' : datasets.load_from_disk(ds_path + '/gpt3-test-conv-ds'),\n",
    "    #'llama3-baseline' : datasets.load_from_disk(ds_path + '/baseline-llama3-test-conv-ds'),\n",
    "    'llama3-baseline-adv-prompt':datasets.load_from_disk(ds_path + '/baseline-advanced-prompt-llama3-test-conv-ds/'),\n",
    "    #'ft-40k-llama3-on-deepseek' :datasets.load_from_disk(ds_path + '/ft-40k-llama3-test-conv-ds'),\n",
    "    'ft-llama3-on-deepseek' :datasets.load_from_disk(ds_path + '/ft-llama3-test-conv-ds'),\n",
    "    'qwen-baseline-adv-prompt':datasets.load_from_disk(ds_path + '/baseline-qwen-test-conv-ds'),\n",
    "    #'ft-qwen-on-deepseek' :datasets.load_from_disk(ds_path + '/ft-40k-qwen-test-conv-ds/'),\n",
    "    'ft-qwen-on-deepseek' :datasets.load_from_disk(ds_path + '/ft-qwen-full-ds-training-test-conv-ds'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdd11301-e6d7-4edf-848f-52455b32c433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generated_convs['ft-llama3-on-deepseek'] = generated_convs['ft-llama3-on-deepseek'].map(lambda row: {'conversation': '\\n\\n'.join(['{}: {}'.format('Journalist', x['content']) if x['role'] == 'assistant' else '{}: {}'.format('Researcher', x['content']) for x in row['generated_conversation'][1:]])})\n",
    "# generated_convs['llama3-baseline'] = generated_convs['llama3-baseline'].map(lambda row: {'conversation': '\\n\\n'.join(['{}: {}'.format('Journalist', x['content']) if x['role'] == 'assistant' else '{}: {}'.format('Researcher', x['content']) for x in row['generated_conversation'][1:]])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a75face6-1b8a-407b-8aab-c199db984634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generated_convs['ft-40k-llama3-on-deepseek'] = generated_convs['ft-40k-llama3-on-deepseek'].map(lambda row: {'pr-article': paper_id_to_article[row['paper_id']]})\n",
    "generated_convs['ft-llama3-on-deepseek'] = generated_convs['ft-llama3-on-deepseek'].map(lambda row: {'pr-article': paper_id_to_article[row['paper_id']]})\n",
    "generated_convs['llama3-baseline-adv-prompt'] = generated_convs['llama3-baseline-adv-prompt'].map(lambda row: {'pr-article': paper_id_to_article[row['paper_id']]})\n",
    "generated_convs['qwen-baseline-adv-prompt'] = generated_convs['qwen-baseline-adv-prompt'].map(lambda row: {'pr-article': paper_id_to_article[row['paper_id']]})\n",
    "generated_convs['ft-qwen-on-deepseek'] = generated_convs['ft-qwen-on-deepseek'].map(lambda row: {'pr-article': paper_id_to_article[row['paper_id']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d988904a-1828-48d3-a116-647e7e6fa43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalaute_convs(datasets):\n",
    "    eval_results = {}\n",
    "    for name, ds in datasets.items():\n",
    "        eval_results[name] = utils.evaluate_conv(ds['conversation'], None, ds['pr-article'])\n",
    "\n",
    "    print(tabulate(\n",
    "        [[name] + list(eval_res.values())[:3] for name, eval_res in eval_results.items()],\n",
    "        headers=['Prompt', 'Rouge-1', 'Rouge-L', 'BERT-f1']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb826256-8a10-420b-ac7d-877d5713593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt                        Rouge-1    Rouge-L    BERT-f1\n",
      "--------------------------  ---------  ---------  ---------\n",
      "llama3-baseline-adv-prompt      0.337      0.145      0.82\n",
      "ft-llama3-on-deepseek           0.346      0.148      0.821\n",
      "qwen-baseline-adv-prompt        0.3        0.127      0.824\n",
      "ft-qwen-on-deepseek             0.28       0.125      0.808\n"
     ]
    }
   ],
   "source": [
    "all_synth_conversations = evalaute_convs(generated_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "32a77cb4-4e31-4091-b9e8-e662288acc4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3364615b0207466a858c5c4a9027d629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf4eaf8be6e447398a41c4ca564ca8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d43faa6d2dc47daaad571312743dbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a592d17e49b0451e89cddc162e0609ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a128fa0a243349a997af5b1406ecff4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8026180959f44882b38f9c34b7153a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt                        Rouge-1    Rouge-L    BERT-f1\n",
      "--------------------------  ---------  ---------  ---------\n",
      "llama3-baseline                 0.333      0.146      0.819\n",
      "llama3-baseline-adv-prompt      0.337      0.145      0.82\n",
      "ft-40k-llama3-on-deepseek       0.425      0.162      0.83\n",
      "qwen-baseline-adv-prompt        0.3        0.127      0.824\n",
      "ft-qwen-on-deepseek             0.397      0.152      0.83\n"
     ]
    }
   ],
   "source": [
    "all_synth_conversations = evalaute_convs(generated_convs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e7db3-243a-4e96-83d7-8dc0af440a35",
   "metadata": {},
   "source": [
    "#### LLM-based Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a66dbe-3631-431e-b1c0-2114b633b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = '/mnt/swordfish-pool2/milad/communicating-science-to-the-public'\n",
    "generated_convs = {\n",
    "    'llama3-baseline-adv-prompt':[datasets.load_from_disk(ds_path + '/baseline-advanced-prompt-llama3-test-conv-ds/'), ds_path + '/baseline-advanced-prompt-llama3-test-conv-ds/'],\n",
    "    'qwen-baseline-adv-prompt':[datasets.load_from_disk(ds_path + '/baseline-qwen-test-conv-ds/'), ds_path + '/baseline-qwen-test-conv-ds/'],\n",
    "    #'ft-40k-llama3-on-deepseek' :[datasets.load_from_disk(ds_path + '/ft-40k-llama3-test-conv-ds/'),ds_path +  '/ft-40k-llama3-test-conv-ds/'],\n",
    "    #'ft-40k-qwen-on-deepseek' :[datasets.load_from_disk(ds_path + '/ft-40k-qwen-test-conv-ds/'),ds_path +  '/ft-40k-qwen-test-conv-ds/'],\n",
    "    'ft-llama3-on-deepseek' :[datasets.load_from_disk(ds_path + '/ft-llama3-test-conv-ds/'),ds_path +  '/ft-llama3-test-conv-ds/'],\n",
    "    'ft-qwen-on-deepseek' :[datasets.load_from_disk(ds_path + '/ft-qwen-full-ds-training-test-conv-ds/'),ds_path +  '/ft-qwen-full-ds-training-test-conv-ds'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afc2599f-f340-4833-8b54-2eb9527621a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated_convs['ft-llama3-on-deepseek'][0] = generated_convs['ft-llama3-on-deepseek'][0].map(lambda row: {'conversation': '\\n\\n'.join(['{}: {}'.format('Journalist', x['content']) if x['role'] == 'assistant' else '{}: {}'.format('Researcher', x['content']) for x in row['generated_conversation'][1:]])})\n",
    "# generated_convs['llama3-baseline'][0] = generated_convs['llama3-baseline'][0].map(lambda row: {'conversation': '\\n\\n'.join(['{}: {}'.format('Journalist', x['content']) if x['role'] == 'assistant' else '{}: {}'.format('Researcher', x['content']) for x in row['generated_conversation'][1:]])})\n",
    "# generated_convs['gpt3-baseline'][0] = generated_convs['gpt3-baseline'][0].remove_columns(['societal_eval_prompt_scoring_parsed', 'scientific_eval_prompt_scoring_parsed', 'clarity_eval_prompt_scoring_parsed'])\n",
    "# generated_convs['llama3-baseline'][0] = generated_convs['llama3-baseline'][0].remove_columns(['societal_eval_prompt_scoring_parsed', 'scientific_eval_prompt_scoring_parsed', 'clarity_eval_prompt_scoring_parsed'])\n",
    "# generated_convs['ft-llama3-on-deepseek'][0] = generated_convs['ft-llama3-on-deepseek'][0].remove_columns(['societal_eval_prompt_scoring_parsed', 'scientific_eval_prompt_scoring_parsed', 'clarity_eval_prompt_scoring_parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "78fbf194-f18f-4606-abe2-7349a6cc74a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [43:16<00:00,  5.19s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [40:16<00:00,  4.83s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [42:30<00:00,  5.10s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d04e97cfd841679d03d02c56e61a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [42:49<00:00,  5.14s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [40:06<00:00,  4.81s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [42:26<00:00,  5.09s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8555dbbc9bdf4ffab9847176f52f7266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [35:42<00:00,  4.29s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [33:55<00:00,  4.07s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [36:29<00:00,  4.38s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1761cef9afe84d0bac665f3ce9337e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [36:39<00:00,  4.40s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [33:52<00:00,  4.06s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [35:34<00:00,  4.27s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b669e45d0d4986bab93a83eb8a29f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#                             clarity_eval_prompt    scientific_eval_prompt    societal_eval_prompt    Avg\n",
      "--------------------------  ---------------------  ------------------------  ----------------------  -----\n",
      "llama3-baseline-adv-prompt                   4.19                      2.17                    1.58   2.65\n",
      "qwen-baseline-adv-prompt                     4.18                      2.41                    1.85   2.81\n",
      "ft-40k-llama3-on-deepseek                    4.48                      1.9                     1.75   2.71\n",
      "ft-40k-qwen-on-deepseek                      4.43                      1.94                    1.67   2.68\n"
     ]
    }
   ],
   "source": [
    "prompts_to_eval = [prompts.clarity_eval_prompt, prompts.scientific_context_eval_prompt, prompts.societal_context_eval_prompt]\n",
    "\n",
    "llm_eval_results = llm_based_evaluation(prompts_to_eval, generated_convs, force_generation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93fb0e16-868f-4785-8e58-16cab5f8217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/baseline-advanced-prompt-llama3-test-conv-ds/ from already saved file\n",
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/baseline-qwen-test-conv-ds/ from already saved file\n",
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/ft-40k-llama3-test-conv-ds/ from already saved file\n",
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/ft-40k-qwen-test-conv-ds/ from already saved file\n",
      "#                             clarity_eval_prompt    scientific_eval_prompt    societal_eval_prompt    Avg\n",
      "--------------------------  ---------------------  ------------------------  ----------------------  -----\n",
      "llama3-baseline-adv-prompt                   4.07                      2.3                     1.46   2.61\n",
      "qwen-baseline-adv-prompt                     3.91                      2.39                    1.63   2.64\n",
      "ft-40k-llama3-on-deepseek                    4.52                      1.9                     1.74   2.72\n",
      "ft-40k-qwen-on-deepseek                      4.44                      1.88                    1.7    2.67\n"
     ]
    }
   ],
   "source": [
    "prompts_to_eval = [prompts.clarity_eval_prompt, prompts.scientific_context_eval_prompt, prompts.societal_context_eval_prompt]\n",
    "\n",
    "llm_eval_results = llm_based_evaluation(prompts_to_eval, generated_convs, force_generation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a95478-e067-4758-920f-a8ea72c3cbc7",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467ed59-b9df-40c2-816b-99c85f5232e7",
   "metadata": {},
   "source": [
    "#### Evaluating the ground-truth generated convs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04958c7-4af7-4b14-b1a5-06dfda39e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_convs = {'original_deepseek_conv': [datasets.load_from_disk('/mnt/swordfish-pool2/milad/communicating-science-to-the-public/processed_test_ds_sample'), '/mnt/swordfish-pool2/milad/communicating-science-to-the-public/processed_test_ds_sample']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909e4dc2-98a1-4cbb-87c3-3515b40acefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/processed_test_ds_sample from already saved file\n",
      "#                         clarity_eval_prompt    scientific_eval_prompt    societal_eval_prompt    Avg\n",
      "----------------------  ---------------------  ------------------------  ----------------------  -----\n",
      "original_deepseek_conv                   4.52                       2.2                    2.06   2.93\n"
     ]
    }
   ],
   "source": [
    "prompts_to_eval = [prompts.clarity_eval_prompt, prompts.scientific_context_eval_prompt, prompts.societal_context_eval_prompt]\n",
    "\n",
    "llm_eval_gt_results = llm_based_evaluation(prompts_to_eval, gt_convs, force_generation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b35126-3e00-4c63-a1e4-17628dcd18db",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398872ee-7b67-4f28-b8de-60280d9582af",
   "metadata": {},
   "source": [
    "### Analysis of the automatic evalaution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88a09ce7-5a36-4323-a1b1-2bdeb4d69183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add the topic to the data\n",
    "deepseek_conv_dataset = datasets.load_from_disk('/mnt/swordfish-pool2/milad/communicating-science-to-the-public/deepseek-final-conv-ds-cleaned/')\n",
    "paper_id_to_article = {x['id']: x['pr-article'] for x in deepseek_conv_dataset}\n",
    "paper_id_to_topic = {x['id']: x['Topic'] for x in deepseek_conv_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd6b765c-2e9a-479a-8032-24247d419e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = '/mnt/swordfish-pool2/milad/communicating-science-to-the-public'\n",
    "generated_convs = {\n",
    "    'llama3-baseline-adv-prompt':[datasets.load_from_disk(ds_path + '/baseline-advanced-prompt-llama3-test-conv-ds/'), ds_path + '/baseline-advanced-prompt-llama3-test-conv-ds/'],\n",
    "    'qwen-baseline-adv-prompt':[datasets.load_from_disk(ds_path + '/baseline-qwen-test-conv-ds/'), ds_path + '/baseline-qwen-test-conv-ds/'],\n",
    "    'ft-llama3-on-deepseek' :[datasets.load_from_disk(ds_path + '/ft-llama3-test-conv-ds/'),ds_path +  '/ft-llama3-test-conv-ds/'],\n",
    "    'ft-qwen-on-deepseek' :[datasets.load_from_disk(ds_path + '/ft-40k-qwen-test-conv-ds/'),ds_path +  '/ft-40k-qwen-test-conv-ds/'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0806f146-d067-40ab-bab4-ea78e34e1afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dceffc456bff42d9a65c6256a554b3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0983c4ca35477092d1cd9594094ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27604813681e42d5aeb55cd577f1f0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bae25e067c4e3991999478014e6432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_convs['llama3-baseline-adv-prompt'][0] = generated_convs['llama3-baseline-adv-prompt'][0].map(lambda row: {'topic': paper_id_to_topic[row['paper_id']]})\n",
    "generated_convs['qwen-baseline-adv-prompt'][0] = generated_convs['qwen-baseline-adv-prompt'][0].map(lambda row: {'topic': paper_id_to_topic[row['paper_id']]})\n",
    "generated_convs['ft-llama3-on-deepseek'][0] = generated_convs['ft-llama3-on-deepseek'][0].map(lambda row: {'topic': paper_id_to_topic[row['paper_id']]})\n",
    "generated_convs['ft-qwen-on-deepseek'][0] = generated_convs['ft-qwen-on-deepseek'][0].map(lambda row: {'topic': paper_id_to_topic[row['paper_id']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78c3fc78-47c7-42af-94d0-2dfb3f88877d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/baseline-advanced-prompt-llama3-test-conv-ds/ from already saved file\n",
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/baseline-qwen-test-conv-ds/ from already saved file\n",
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/ft-llama3-test-conv-ds/ from already saved file\n",
      "Loading /mnt/swordfish-pool2/milad/communicating-science-to-the-public/ft-40k-qwen-test-conv-ds/ from already saved file\n",
      "#                             clarity_eval_prompt    scientific_eval_prompt    societal_eval_prompt    Avg\n",
      "--------------------------  ---------------------  ------------------------  ----------------------  -----\n",
      "llama3-baseline-adv-prompt                   4.19                      2.17                    1.58   2.65\n",
      "qwen-baseline-adv-prompt                     4.18                      2.41                    1.85   2.81\n",
      "ft-llama3-on-deepseek                        4.2                       2.04                    1.74   2.66\n",
      "ft-qwen-on-deepseek                          4.43                      1.94                    1.67   2.68\n"
     ]
    }
   ],
   "source": [
    "prompts_to_eval = [prompts.clarity_eval_prompt, prompts.scientific_context_eval_prompt, prompts.societal_context_eval_prompt]\n",
    "\n",
    "llm_eval_results = llm_based_evaluation(prompts_to_eval, generated_convs, force_generation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "beb30418-e240-4895-ab38-b19102cd6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#                             clarity_eval_prompt    scientific_eval_prompt    societal_eval_prompt    Avg\n",
      "--------------------------  ---------------------  ------------------------  ----------------------  -----\n",
      "llama3-baseline-adv-prompt                   4.19                      2.17                    1.58   2.65\n",
      "qwen-baseline-adv-prompt                     4.18                      2.41                    1.85   2.81\n",
      "ft-llama3-on-deepseek                        4.2                       2.04                    1.74   2.66\n",
      "ft-qwen-on-deepseek                          4.43                      1.94                    1.67   2.68\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(\n",
    "        [[name] + get_llm_avg_scores(res, prompts_to_eval) for name, res in llm_eval_results.items()],\n",
    "        headers=['#'] + [p['strategy_name'] for p in prompts_to_eval] + ['Avg']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fe88bd9-10e4-457d-9ee5-6096816e25fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b34da5793e4e24b1ed3e9ecf6b9029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'topic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(paper_id_to_topic\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(topic)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tabulate(\n\u001b[0;32m----> 4\u001b[0m         [[name] \u001b[38;5;241m+\u001b[39m get_llm_avg_scores(\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mtopic\u001b[49m\u001b[43m)\u001b[49m, prompts_to_eval) \u001b[38;5;28;01mfor\u001b[39;00m name, res \u001b[38;5;129;01min\u001b[39;00m llm_eval_results\u001b[38;5;241m.\u001b[39mitems()],\n\u001b[1;32m      5\u001b[0m         headers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrategy_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts_to_eval] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m     ))\n",
      "File \u001b[0;32m/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datasets/fingerprint.py:442\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datasets/arrow_dataset.py:3688\u001b[0m, in \u001b[0;36mDataset.filter\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 3688\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_indices_from_mask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3695\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3696\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3697\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muint64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3710\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3712\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFilter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3715\u001b[0m new_dataset \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   3716\u001b[0m new_dataset\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datasets/arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3069\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3070\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3073\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3074\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3075\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datasets/arrow_dataset.py:3476\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3472\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3473\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3474\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3475\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3476\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3480\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3485\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datasets/arrow_dataset.py:3338\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3337\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3338\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3340\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3341\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3342\u001b[0m     }\n",
      "File \u001b[0;32m/mnt/swordfish-pool2/milad/conda-envs/datadreamer/lib/python3.12/site-packages/datasets/arrow_dataset.py:6327\u001b[0m, in \u001b[0;36mget_indices_from_mask_function\u001b[0;34m(function, batched, with_indices, with_rank, input_columns, indices_mapping, *args, **fn_kwargs)\u001b[0m\n\u001b[1;32m   6325\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   6326\u001b[0m             additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 6327\u001b[0m         mask\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   6328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6329\u001b[0m     \u001b[38;5;66;03m# inputs is a list of columns\u001b[39;00m\n\u001b[1;32m   6330\u001b[0m     columns: List[List] \u001b[38;5;241m=\u001b[39m inputs\n",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(paper_id_to_topic\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(topic)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tabulate(\n\u001b[0;32m----> 4\u001b[0m         [[name] \u001b[38;5;241m+\u001b[39m get_llm_avg_scores(res\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39mtopic), prompts_to_eval) \u001b[38;5;28;01mfor\u001b[39;00m name, res \u001b[38;5;129;01min\u001b[39;00m llm_eval_results\u001b[38;5;241m.\u001b[39mitems()],\n\u001b[1;32m      5\u001b[0m         headers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrategy_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts_to_eval] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m     ))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'topic'"
     ]
    }
   ],
   "source": [
    "for topic in set(paper_id_to_topic.values()):\n",
    "    print(topic)\n",
    "    print(tabulate(\n",
    "        [[name] + get_llm_avg_scores(res.filter(lambda row: row['topic'] ==topic), prompts_to_eval) for name, res in llm_eval_results.items()],\n",
    "        headers=['#'] + [p['strategy_name'] for p in prompts_to_eval] + ['Avg']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f9968-13ee-41da-8ba3-50ff2d43f070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
